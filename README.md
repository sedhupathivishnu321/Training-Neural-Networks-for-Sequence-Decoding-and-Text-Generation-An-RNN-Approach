# Training-Neural-Networks-for-Sequence-Decoding-and-Text-Generation-An-RNN-Approach
By training RNN and LSTM models, we will generate human-readable text from encoded inputs. This project will also involve dataset creation and handling unrecognized sequences in preprocessing. The end goal is a model capable of accurately reconstructing complex encoded passages.
